{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdECtyZ0PLH",
        "outputId": "25026bd6-f669-4333-e523-3f3a276e1f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” CSV ë¡œë“œ ì™„ë£Œ: 768ê°œ í•­ëª©\n",
            "\n",
            "âœ… ìµœì¢… ë¡œë”© ì™„ë£Œ\n",
            "ðŸ–¼ï¸  ì´ë¯¸ì§€ ìˆ˜: 768\n",
            "ðŸ“  ì´ë¯¸ì§€ í˜•íƒœ: (768, 64, 64, 3)\n",
            "ðŸ·ï¸  ë¼ë²¨ í˜•íƒœ: (768,)\n",
            "ðŸ”¢  ë¼ë²¨ ë¶„í¬: [  0 410  57 301]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "CSV_PATH = \"/content/data/data/drive_log_merged.csv\"\n",
        "DATA_DIR_1 = \"/content/data/data\"   # data1 -> data\n",
        "DATA_DIR_2 = \"/content/data/data2\"  # data2 ê·¸ëŒ€ë¡œ\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(f\"ðŸ” CSV ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ í•­ëª©\")\n",
        "\n",
        "def get_actual_path(frame_path):\n",
        "    if frame_path.startswith(\"data1/\"):\n",
        "        # data1 -> data\n",
        "        relative_path = frame_path.replace(\"data1/\", \"\")\n",
        "        return os.path.join(DATA_DIR_1, relative_path)\n",
        "    elif frame_path.startswith(\"data2/\"):\n",
        "        # data2 ê·¸ëŒ€ë¡œ\n",
        "        relative_path = frame_path.replace(\"data2/\", \"\")\n",
        "        return os.path.join(DATA_DIR_2, relative_path)\n",
        "    else:\n",
        "        # ê·¸ ì™¸ëŠ” ê·¸ëƒ¥ ê¸°ë³¸ ë°ì´í„° í´ë”ì— ë¶™ìž„\n",
        "        return os.path.join(DATA_DIR_1, frame_path)\n",
        "\n",
        "def load_data(df):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {\"left\": 0, \"center\": 1, \"right\": 2, \"stop\": 3}\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        img_path = get_actual_path(row['frame'])\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"ì´ë¯¸ì§€ ì—†ìŒ: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"ì´ë¯¸ì§€ ì½ê¸° ì‹¤íŒ¨: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.resize(img, (64, 64))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        images.append(img)\n",
        "\n",
        "        label_str = str(row['label']).lower().strip()\n",
        "        label = label_map.get(label_str, -1)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels, dtype=int)\n",
        "\n",
        "X, y = load_data(df)\n",
        "\n",
        "valid_idx = y >= 0\n",
        "X = X[valid_idx]\n",
        "y = y[valid_idx]\n",
        "\n",
        "print(f\"\\nâœ… ìµœì¢… ë¡œë”© ì™„ë£Œ\")\n",
        "print(f\"ðŸ–¼ï¸  ì´ë¯¸ì§€ ìˆ˜: {len(X)}\")\n",
        "print(f\"ðŸ“  ì´ë¯¸ì§€ í˜•íƒœ: {X.shape}\")\n",
        "print(f\"ðŸ·ï¸  ë¼ë²¨ í˜•íƒœ: {y.shape}\")\n",
        "print(f\"ðŸ”¢  ë¼ë²¨ ë¶„í¬: {np.bincount(y)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ê²½ë¡œ ì„¤ì •\n",
        "CSV_PATH = \"/content/data/data/drive_log_merged.csv\"\n",
        "DATA_DIR_1 = \"/content/data/data\"    # data1 ëŒ€ì‹  data í´ë”\n",
        "DATA_DIR_2 = \"/content/data/data2\"   # data2 í´ë”\n",
        "\n",
        "# 1) ì´ë¯¸ì§€ ê²½ë¡œ ë§¤í•‘ í•¨ìˆ˜\n",
        "def get_actual_path(frame_path):\n",
        "    if frame_path.startswith(\"data1/\"):\n",
        "        relative_path = frame_path.replace(\"data1/\", \"\")\n",
        "        return os.path.join(DATA_DIR_1, relative_path)\n",
        "    elif frame_path.startswith(\"data2/\"):\n",
        "        relative_path = frame_path.replace(\"data2/\", \"\")\n",
        "        return os.path.join(DATA_DIR_2, relative_path)\n",
        "    else:\n",
        "        # ì˜ˆì™¸ ì²˜ë¦¬: ê·¸ëƒ¥ DATA_DIR_1ì— ë¶™ìž„\n",
        "        return os.path.join(DATA_DIR_1, frame_path)\n",
        "\n",
        "# 2) ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í´ëž˜ìŠ¤\n",
        "class DriveDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        import pandas as pd\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.label_map = {\"left\": 0, \"center\": 1, \"right\": 2, \"stop\": 3}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_path = self.data.iloc[idx, 0]  # 'frame' ì»¬ëŸ¼\n",
        "        img_path = get_actual_path(frame_path)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        label_str = str(self.data.iloc[idx, 2]).lower().strip()\n",
        "        label = self.label_map.get(label_str, -1)\n",
        "        if label == -1:\n",
        "            raise ValueError(f\"Invalid label '{label_str}' at index {idx}\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# 3) ì´ë¯¸ì§€ ì „ì²˜ë¦¬ + Augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 4) ë°ì´í„°ì…‹ ìƒì„± ë° ë¶„í• \n",
        "dataset = DriveDataset(csv_file=CSV_PATH, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "\n",
        "# 5) Dropout ì¶”ê°€ CNN ëª¨ë¸ ì •ì˜\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 64)\n",
        "        self.fc2 = nn.Linear(64, 4)  # 4 í´ëž˜ìŠ¤\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "print(\"âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlWeqUyv3r3e",
        "outputId": "2ca23492-03b6-4c49-d866-b09f115b2e15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPUë¡œ, ì•„ë‹ˆë©´ CPUë¡œ ì„¤ì •\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì € ì •ì˜\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 70\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # --- í•™ìŠµ ëª¨ë“œ ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss /= total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # --- í‰ê°€ ëª¨ë“œ ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{num_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg6JCGkJ4B4V",
        "outputId": "25e15bd9-a377-4db7-d92d-6c76bbdae5f5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/70] Train Loss: 0.8424, Train Acc: 0.6026 Val Loss: 0.4641, Val Acc: 0.8571\n",
            "Epoch [2/70] Train Loss: 0.4268, Train Acc: 0.8192 Val Loss: 0.3767, Val Acc: 0.7727\n",
            "Epoch [3/70] Train Loss: 0.3517, Train Acc: 0.8599 Val Loss: 0.3273, Val Acc: 0.8506\n",
            "Epoch [4/70] Train Loss: 0.3284, Train Acc: 0.8502 Val Loss: 0.3042, Val Acc: 0.8506\n",
            "Epoch [5/70] Train Loss: 0.2959, Train Acc: 0.8632 Val Loss: 0.3381, Val Acc: 0.8506\n",
            "Epoch [6/70] Train Loss: 0.3150, Train Acc: 0.8404 Val Loss: 0.3026, Val Acc: 0.8506\n",
            "Epoch [7/70] Train Loss: 0.2994, Train Acc: 0.8567 Val Loss: 0.2919, Val Acc: 0.8506\n",
            "Epoch [8/70] Train Loss: 0.2907, Train Acc: 0.8599 Val Loss: 0.3103, Val Acc: 0.8506\n",
            "Epoch [9/70] Train Loss: 0.2778, Train Acc: 0.8583 Val Loss: 0.2689, Val Acc: 0.8701\n",
            "Epoch [10/70] Train Loss: 0.2597, Train Acc: 0.8632 Val Loss: 0.2599, Val Acc: 0.8506\n",
            "Epoch [11/70] Train Loss: 0.2425, Train Acc: 0.8713 Val Loss: 0.2574, Val Acc: 0.8506\n",
            "Epoch [12/70] Train Loss: 0.2424, Train Acc: 0.8713 Val Loss: 0.2464, Val Acc: 0.8506\n",
            "Epoch [13/70] Train Loss: 0.2417, Train Acc: 0.8632 Val Loss: 0.2420, Val Acc: 0.8506\n",
            "Epoch [14/70] Train Loss: 0.2327, Train Acc: 0.8713 Val Loss: 0.2509, Val Acc: 0.8701\n",
            "Epoch [15/70] Train Loss: 0.2417, Train Acc: 0.8697 Val Loss: 0.2496, Val Acc: 0.8506\n",
            "Epoch [16/70] Train Loss: 0.2266, Train Acc: 0.8616 Val Loss: 0.2177, Val Acc: 0.8571\n",
            "Epoch [17/70] Train Loss: 0.2360, Train Acc: 0.8648 Val Loss: 0.2480, Val Acc: 0.8506\n",
            "Epoch [18/70] Train Loss: 0.2434, Train Acc: 0.8713 Val Loss: 0.2448, Val Acc: 0.8506\n",
            "Epoch [19/70] Train Loss: 0.2111, Train Acc: 0.8697 Val Loss: 0.2197, Val Acc: 0.8571\n",
            "Epoch [20/70] Train Loss: 0.2204, Train Acc: 0.8599 Val Loss: 0.2178, Val Acc: 0.8636\n",
            "Epoch [21/70] Train Loss: 0.2078, Train Acc: 0.8697 Val Loss: 0.2237, Val Acc: 0.8571\n",
            "Epoch [22/70] Train Loss: 0.2096, Train Acc: 0.8746 Val Loss: 0.2123, Val Acc: 0.8571\n",
            "Epoch [23/70] Train Loss: 0.2174, Train Acc: 0.8616 Val Loss: 0.2239, Val Acc: 0.8506\n",
            "Epoch [24/70] Train Loss: 0.2091, Train Acc: 0.8779 Val Loss: 0.2101, Val Acc: 0.8701\n",
            "Epoch [25/70] Train Loss: 0.1995, Train Acc: 0.8876 Val Loss: 0.2071, Val Acc: 0.8766\n",
            "Epoch [26/70] Train Loss: 0.1993, Train Acc: 0.8779 Val Loss: 0.2085, Val Acc: 0.8636\n",
            "Epoch [27/70] Train Loss: 0.2071, Train Acc: 0.8648 Val Loss: 0.2089, Val Acc: 0.8506\n",
            "Epoch [28/70] Train Loss: 0.1913, Train Acc: 0.8909 Val Loss: 0.2074, Val Acc: 0.8377\n",
            "Epoch [29/70] Train Loss: 0.2028, Train Acc: 0.8746 Val Loss: 0.2068, Val Acc: 0.8506\n",
            "Epoch [30/70] Train Loss: 0.2082, Train Acc: 0.8762 Val Loss: 0.2121, Val Acc: 0.8506\n",
            "Epoch [31/70] Train Loss: 0.2051, Train Acc: 0.8795 Val Loss: 0.2069, Val Acc: 0.8506\n",
            "Epoch [32/70] Train Loss: 0.1956, Train Acc: 0.8632 Val Loss: 0.2042, Val Acc: 0.8636\n",
            "Epoch [33/70] Train Loss: 0.1913, Train Acc: 0.8779 Val Loss: 0.2041, Val Acc: 0.8506\n",
            "Epoch [34/70] Train Loss: 0.2188, Train Acc: 0.8713 Val Loss: 0.2179, Val Acc: 0.8506\n",
            "Epoch [35/70] Train Loss: 0.1994, Train Acc: 0.8664 Val Loss: 0.2075, Val Acc: 0.8506\n",
            "Epoch [36/70] Train Loss: 0.2007, Train Acc: 0.8697 Val Loss: 0.2074, Val Acc: 0.8506\n",
            "Epoch [37/70] Train Loss: 0.1974, Train Acc: 0.8876 Val Loss: 0.2068, Val Acc: 0.8506\n",
            "Epoch [38/70] Train Loss: 0.1910, Train Acc: 0.8795 Val Loss: 0.2093, Val Acc: 0.8506\n",
            "Epoch [39/70] Train Loss: 0.1926, Train Acc: 0.8632 Val Loss: 0.3016, Val Acc: 0.8506\n",
            "Epoch [40/70] Train Loss: 0.2548, Train Acc: 0.8616 Val Loss: 0.2403, Val Acc: 0.8506\n",
            "Epoch [41/70] Train Loss: 0.2257, Train Acc: 0.8713 Val Loss: 0.2181, Val Acc: 0.8506\n",
            "Epoch [42/70] Train Loss: 0.1923, Train Acc: 0.8811 Val Loss: 0.2080, Val Acc: 0.8506\n",
            "Epoch [43/70] Train Loss: 0.1951, Train Acc: 0.8730 Val Loss: 0.2046, Val Acc: 0.8701\n",
            "Epoch [44/70] Train Loss: 0.2002, Train Acc: 0.8746 Val Loss: 0.2074, Val Acc: 0.8442\n",
            "Epoch [45/70] Train Loss: 0.2011, Train Acc: 0.8795 Val Loss: 0.2044, Val Acc: 0.8636\n",
            "Epoch [46/70] Train Loss: 0.1909, Train Acc: 0.8730 Val Loss: 0.2064, Val Acc: 0.8506\n",
            "Epoch [47/70] Train Loss: 0.2038, Train Acc: 0.8681 Val Loss: 0.2046, Val Acc: 0.8636\n",
            "Epoch [48/70] Train Loss: 0.1983, Train Acc: 0.8697 Val Loss: 0.2043, Val Acc: 0.8636\n",
            "Epoch [49/70] Train Loss: 0.1927, Train Acc: 0.8730 Val Loss: 0.2017, Val Acc: 0.8831\n",
            "Epoch [50/70] Train Loss: 0.1927, Train Acc: 0.8599 Val Loss: 0.2024, Val Acc: 0.8766\n",
            "Epoch [51/70] Train Loss: 0.1910, Train Acc: 0.8681 Val Loss: 0.2015, Val Acc: 0.8636\n",
            "Epoch [52/70] Train Loss: 0.2044, Train Acc: 0.8730 Val Loss: 0.2043, Val Acc: 0.8506\n",
            "Epoch [53/70] Train Loss: 0.1956, Train Acc: 0.8762 Val Loss: 0.2091, Val Acc: 0.8312\n",
            "Epoch [54/70] Train Loss: 0.2000, Train Acc: 0.8648 Val Loss: 0.2052, Val Acc: 0.8312\n",
            "Epoch [55/70] Train Loss: 0.1947, Train Acc: 0.8664 Val Loss: 0.2061, Val Acc: 0.8571\n",
            "Epoch [56/70] Train Loss: 0.2015, Train Acc: 0.8762 Val Loss: 0.2042, Val Acc: 0.8506\n",
            "Epoch [57/70] Train Loss: 0.1935, Train Acc: 0.8746 Val Loss: 0.2037, Val Acc: 0.8506\n",
            "Epoch [58/70] Train Loss: 0.1938, Train Acc: 0.8697 Val Loss: 0.2059, Val Acc: 0.8377\n",
            "Epoch [59/70] Train Loss: 0.1898, Train Acc: 0.8664 Val Loss: 0.2060, Val Acc: 0.8506\n",
            "Epoch [60/70] Train Loss: 0.1891, Train Acc: 0.8795 Val Loss: 0.2022, Val Acc: 0.8571\n",
            "Epoch [61/70] Train Loss: 0.1946, Train Acc: 0.8599 Val Loss: 0.2083, Val Acc: 0.8506\n",
            "Epoch [62/70] Train Loss: 0.2011, Train Acc: 0.8616 Val Loss: 0.2060, Val Acc: 0.8506\n",
            "Epoch [63/70] Train Loss: 0.2020, Train Acc: 0.8583 Val Loss: 0.2048, Val Acc: 0.8442\n",
            "Epoch [64/70] Train Loss: 0.2000, Train Acc: 0.8697 Val Loss: 0.2063, Val Acc: 0.8506\n",
            "Epoch [65/70] Train Loss: 0.2015, Train Acc: 0.8746 Val Loss: 0.2054, Val Acc: 0.8506\n",
            "Epoch [66/70] Train Loss: 0.1984, Train Acc: 0.8746 Val Loss: 0.2047, Val Acc: 0.8506\n",
            "Epoch [67/70] Train Loss: 0.1937, Train Acc: 0.8730 Val Loss: 0.2050, Val Acc: 0.8312\n",
            "Epoch [68/70] Train Loss: 0.1974, Train Acc: 0.8550 Val Loss: 0.2047, Val Acc: 0.8506\n",
            "Epoch [69/70] Train Loss: 0.1928, Train Acc: 0.8664 Val Loss: 0.2046, Val Acc: 0.8766\n",
            "Epoch [70/70] Train Loss: 0.1948, Train Acc: 0.8583 Val Loss: 0.2045, Val Acc: 0.8506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (ê¸°ì¡´ ì½”ë“œ ëë‚œ ë¶€ë¶„ ë°”ë¡œ ì•„ëž˜ì— ì¶”ê°€)\n",
        "\n",
        "# --- Fine-tuning ë‹¨ê³„ ì‹œìž‘ ---\n",
        "print(\"\\n=== Fine-tuning ë‹¨ê³„ ì‹œìž‘ ===\")\n",
        "\n",
        "# 1. ëª¨ë“  íŒŒë¼ë¯¸í„° í•™ìŠµ ê°€ëŠ¥í•˜ë„ë¡ ë³€ê²½ (unfreeze)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 2. ì˜µí‹°ë§ˆì´ì € ìž¬ì •ì˜ (í•™ìŠµë¥  ë§¤ìš° ìž‘ê²Œ ì„¤ì •)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "num_finetune_epochs = 10\n",
        "\n",
        "for epoch in range(1, num_finetune_epochs + 1):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss /= total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f\"[Fine-tune Epoch {epoch}/{num_finetune_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "DbehN97o6PrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b7f7a1-d650-47ce-cfd0-27119cabe690"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fine-tuning ë‹¨ê³„ ì‹œìž‘ ===\n",
            "[Fine-tune Epoch 1/10] Train Loss: 0.1943, Train Acc: 0.8697 Val Loss: 0.2045, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 2/10] Train Loss: 0.1881, Train Acc: 0.8567 Val Loss: 0.2037, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 3/10] Train Loss: 0.1878, Train Acc: 0.8746 Val Loss: 0.2043, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 4/10] Train Loss: 0.1876, Train Acc: 0.8697 Val Loss: 0.2045, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 5/10] Train Loss: 0.1912, Train Acc: 0.8697 Val Loss: 0.2042, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 6/10] Train Loss: 0.1918, Train Acc: 0.8697 Val Loss: 0.2039, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 7/10] Train Loss: 0.1870, Train Acc: 0.8730 Val Loss: 0.2040, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 8/10] Train Loss: 0.1894, Train Acc: 0.8583 Val Loss: 0.2038, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 9/10] Train Loss: 0.1870, Train Acc: 0.8827 Val Loss: 0.2041, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 10/10] Train Loss: 0.1861, Train Acc: 0.8811 Val Loss: 0.2036, Val Acc: 0.8506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# í•™ìŠµ ì™„ë£Œ í›„ ëª¨ë¸ ì €ìž¥\n",
        "torch.save(model.state_dict(), \"drive_model.pth\")\n",
        "print(\"ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: drive_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgOJ65mx7KIE",
        "outputId": "cbaccca9-e6ce-4900-bc96-7141c4495db7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ëª¨ë¸ ì €ìž¥ ì™„ë£Œ: drive_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX1lz-G_p3GA",
        "outputId": "422697a1-1698-413c-a6e9-7e1b1e88cda4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d49N6W70p5d6",
        "outputId": "3bd88d40-282d-4bb1-c549-df255a071db3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,305 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,561 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,747 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,798 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,051 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,253 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.2 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,994 kB]\n",
            "Fetched 23.2 MB in 3s (6,622 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    }
  ]
}