{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdECtyZ0PLH",
        "outputId": "25026bd6-f669-4333-e523-3f3a276e1f7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 CSV 로드 완료: 768개 항목\n",
            "\n",
            "✅ 최종 로딩 완료\n",
            "🖼️  이미지 수: 768\n",
            "📏  이미지 형태: (768, 64, 64, 3)\n",
            "🏷️  라벨 형태: (768,)\n",
            "🔢  라벨 분포: [  0 410  57 301]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "CSV_PATH = \"/content/data/data/drive_log_merged.csv\"\n",
        "DATA_DIR_1 = \"/content/data/data\"   # data1 -> data\n",
        "DATA_DIR_2 = \"/content/data/data2\"  # data2 그대로\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(f\"🔍 CSV 로드 완료: {len(df)}개 항목\")\n",
        "\n",
        "def get_actual_path(frame_path):\n",
        "    if frame_path.startswith(\"data1/\"):\n",
        "        # data1 -> data\n",
        "        relative_path = frame_path.replace(\"data1/\", \"\")\n",
        "        return os.path.join(DATA_DIR_1, relative_path)\n",
        "    elif frame_path.startswith(\"data2/\"):\n",
        "        # data2 그대로\n",
        "        relative_path = frame_path.replace(\"data2/\", \"\")\n",
        "        return os.path.join(DATA_DIR_2, relative_path)\n",
        "    else:\n",
        "        # 그 외는 그냥 기본 데이터 폴더에 붙임\n",
        "        return os.path.join(DATA_DIR_1, frame_path)\n",
        "\n",
        "def load_data(df):\n",
        "    images = []\n",
        "    labels = []\n",
        "    label_map = {\"left\": 0, \"center\": 1, \"right\": 2, \"stop\": 3}\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        img_path = get_actual_path(row['frame'])\n",
        "        if not os.path.exists(img_path):\n",
        "            print(f\"이미지 없음: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"이미지 읽기 실패: {img_path}\")\n",
        "            continue\n",
        "\n",
        "        img = cv2.resize(img, (64, 64))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        images.append(img)\n",
        "\n",
        "        label_str = str(row['label']).lower().strip()\n",
        "        label = label_map.get(label_str, -1)\n",
        "        labels.append(label)\n",
        "\n",
        "    return np.array(images), np.array(labels, dtype=int)\n",
        "\n",
        "X, y = load_data(df)\n",
        "\n",
        "valid_idx = y >= 0\n",
        "X = X[valid_idx]\n",
        "y = y[valid_idx]\n",
        "\n",
        "print(f\"\\n✅ 최종 로딩 완료\")\n",
        "print(f\"🖼️  이미지 수: {len(X)}\")\n",
        "print(f\"📏  이미지 형태: {X.shape}\")\n",
        "print(f\"🏷️  라벨 형태: {y.shape}\")\n",
        "print(f\"🔢  라벨 분포: {np.bincount(y)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 경로 설정\n",
        "CSV_PATH = \"/content/data/data/drive_log_merged.csv\"\n",
        "DATA_DIR_1 = \"/content/data/data\"    # data1 대신 data 폴더\n",
        "DATA_DIR_2 = \"/content/data/data2\"   # data2 폴더\n",
        "\n",
        "# 1) 이미지 경로 매핑 함수\n",
        "def get_actual_path(frame_path):\n",
        "    if frame_path.startswith(\"data1/\"):\n",
        "        relative_path = frame_path.replace(\"data1/\", \"\")\n",
        "        return os.path.join(DATA_DIR_1, relative_path)\n",
        "    elif frame_path.startswith(\"data2/\"):\n",
        "        relative_path = frame_path.replace(\"data2/\", \"\")\n",
        "        return os.path.join(DATA_DIR_2, relative_path)\n",
        "    else:\n",
        "        # 예외 처리: 그냥 DATA_DIR_1에 붙임\n",
        "        return os.path.join(DATA_DIR_1, frame_path)\n",
        "\n",
        "# 2) 커스텀 데이터셋 클래스\n",
        "class DriveDataset(Dataset):\n",
        "    def __init__(self, csv_file, transform=None):\n",
        "        import pandas as pd\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "        self.label_map = {\"left\": 0, \"center\": 1, \"right\": 2, \"stop\": 3}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        frame_path = self.data.iloc[idx, 0]  # 'frame' 컬럼\n",
        "        img_path = get_actual_path(frame_path)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        label_str = str(self.data.iloc[idx, 2]).lower().strip()\n",
        "        label = self.label_map.get(label_str, -1)\n",
        "        if label == -1:\n",
        "            raise ValueError(f\"Invalid label '{label_str}' at index {idx}\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# 3) 이미지 전처리 + Augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])\n",
        "\n",
        "# 4) 데이터셋 생성 및 분할\n",
        "dataset = DriveDataset(csv_file=CSV_PATH, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=32, shuffle=False)\n",
        "\n",
        "# 5) Dropout 추가 CNN 모델 정의\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(32 * 16 * 16, 64)\n",
        "        self.fc2 = nn.Linear(64, 4)  # 4 클래스\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 32 * 16 * 16)\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN()\n",
        "print(\"✅ 모델 준비 완료!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlWeqUyv3r3e",
        "outputId": "2ca23492-03b6-4c49-d866-b09f115b2e15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 모델 준비 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# GPU 사용 가능하면 GPU로, 아니면 CPU로 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 손실함수, 옵티마이저 정의\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "num_epochs = 70\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # --- 학습 모드 ---\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss /= total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    # --- 평가 모드 ---\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{num_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg6JCGkJ4B4V",
        "outputId": "25e15bd9-a377-4db7-d92d-6c76bbdae5f5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/70] Train Loss: 0.8424, Train Acc: 0.6026 Val Loss: 0.4641, Val Acc: 0.8571\n",
            "Epoch [2/70] Train Loss: 0.4268, Train Acc: 0.8192 Val Loss: 0.3767, Val Acc: 0.7727\n",
            "Epoch [3/70] Train Loss: 0.3517, Train Acc: 0.8599 Val Loss: 0.3273, Val Acc: 0.8506\n",
            "Epoch [4/70] Train Loss: 0.3284, Train Acc: 0.8502 Val Loss: 0.3042, Val Acc: 0.8506\n",
            "Epoch [5/70] Train Loss: 0.2959, Train Acc: 0.8632 Val Loss: 0.3381, Val Acc: 0.8506\n",
            "Epoch [6/70] Train Loss: 0.3150, Train Acc: 0.8404 Val Loss: 0.3026, Val Acc: 0.8506\n",
            "Epoch [7/70] Train Loss: 0.2994, Train Acc: 0.8567 Val Loss: 0.2919, Val Acc: 0.8506\n",
            "Epoch [8/70] Train Loss: 0.2907, Train Acc: 0.8599 Val Loss: 0.3103, Val Acc: 0.8506\n",
            "Epoch [9/70] Train Loss: 0.2778, Train Acc: 0.8583 Val Loss: 0.2689, Val Acc: 0.8701\n",
            "Epoch [10/70] Train Loss: 0.2597, Train Acc: 0.8632 Val Loss: 0.2599, Val Acc: 0.8506\n",
            "Epoch [11/70] Train Loss: 0.2425, Train Acc: 0.8713 Val Loss: 0.2574, Val Acc: 0.8506\n",
            "Epoch [12/70] Train Loss: 0.2424, Train Acc: 0.8713 Val Loss: 0.2464, Val Acc: 0.8506\n",
            "Epoch [13/70] Train Loss: 0.2417, Train Acc: 0.8632 Val Loss: 0.2420, Val Acc: 0.8506\n",
            "Epoch [14/70] Train Loss: 0.2327, Train Acc: 0.8713 Val Loss: 0.2509, Val Acc: 0.8701\n",
            "Epoch [15/70] Train Loss: 0.2417, Train Acc: 0.8697 Val Loss: 0.2496, Val Acc: 0.8506\n",
            "Epoch [16/70] Train Loss: 0.2266, Train Acc: 0.8616 Val Loss: 0.2177, Val Acc: 0.8571\n",
            "Epoch [17/70] Train Loss: 0.2360, Train Acc: 0.8648 Val Loss: 0.2480, Val Acc: 0.8506\n",
            "Epoch [18/70] Train Loss: 0.2434, Train Acc: 0.8713 Val Loss: 0.2448, Val Acc: 0.8506\n",
            "Epoch [19/70] Train Loss: 0.2111, Train Acc: 0.8697 Val Loss: 0.2197, Val Acc: 0.8571\n",
            "Epoch [20/70] Train Loss: 0.2204, Train Acc: 0.8599 Val Loss: 0.2178, Val Acc: 0.8636\n",
            "Epoch [21/70] Train Loss: 0.2078, Train Acc: 0.8697 Val Loss: 0.2237, Val Acc: 0.8571\n",
            "Epoch [22/70] Train Loss: 0.2096, Train Acc: 0.8746 Val Loss: 0.2123, Val Acc: 0.8571\n",
            "Epoch [23/70] Train Loss: 0.2174, Train Acc: 0.8616 Val Loss: 0.2239, Val Acc: 0.8506\n",
            "Epoch [24/70] Train Loss: 0.2091, Train Acc: 0.8779 Val Loss: 0.2101, Val Acc: 0.8701\n",
            "Epoch [25/70] Train Loss: 0.1995, Train Acc: 0.8876 Val Loss: 0.2071, Val Acc: 0.8766\n",
            "Epoch [26/70] Train Loss: 0.1993, Train Acc: 0.8779 Val Loss: 0.2085, Val Acc: 0.8636\n",
            "Epoch [27/70] Train Loss: 0.2071, Train Acc: 0.8648 Val Loss: 0.2089, Val Acc: 0.8506\n",
            "Epoch [28/70] Train Loss: 0.1913, Train Acc: 0.8909 Val Loss: 0.2074, Val Acc: 0.8377\n",
            "Epoch [29/70] Train Loss: 0.2028, Train Acc: 0.8746 Val Loss: 0.2068, Val Acc: 0.8506\n",
            "Epoch [30/70] Train Loss: 0.2082, Train Acc: 0.8762 Val Loss: 0.2121, Val Acc: 0.8506\n",
            "Epoch [31/70] Train Loss: 0.2051, Train Acc: 0.8795 Val Loss: 0.2069, Val Acc: 0.8506\n",
            "Epoch [32/70] Train Loss: 0.1956, Train Acc: 0.8632 Val Loss: 0.2042, Val Acc: 0.8636\n",
            "Epoch [33/70] Train Loss: 0.1913, Train Acc: 0.8779 Val Loss: 0.2041, Val Acc: 0.8506\n",
            "Epoch [34/70] Train Loss: 0.2188, Train Acc: 0.8713 Val Loss: 0.2179, Val Acc: 0.8506\n",
            "Epoch [35/70] Train Loss: 0.1994, Train Acc: 0.8664 Val Loss: 0.2075, Val Acc: 0.8506\n",
            "Epoch [36/70] Train Loss: 0.2007, Train Acc: 0.8697 Val Loss: 0.2074, Val Acc: 0.8506\n",
            "Epoch [37/70] Train Loss: 0.1974, Train Acc: 0.8876 Val Loss: 0.2068, Val Acc: 0.8506\n",
            "Epoch [38/70] Train Loss: 0.1910, Train Acc: 0.8795 Val Loss: 0.2093, Val Acc: 0.8506\n",
            "Epoch [39/70] Train Loss: 0.1926, Train Acc: 0.8632 Val Loss: 0.3016, Val Acc: 0.8506\n",
            "Epoch [40/70] Train Loss: 0.2548, Train Acc: 0.8616 Val Loss: 0.2403, Val Acc: 0.8506\n",
            "Epoch [41/70] Train Loss: 0.2257, Train Acc: 0.8713 Val Loss: 0.2181, Val Acc: 0.8506\n",
            "Epoch [42/70] Train Loss: 0.1923, Train Acc: 0.8811 Val Loss: 0.2080, Val Acc: 0.8506\n",
            "Epoch [43/70] Train Loss: 0.1951, Train Acc: 0.8730 Val Loss: 0.2046, Val Acc: 0.8701\n",
            "Epoch [44/70] Train Loss: 0.2002, Train Acc: 0.8746 Val Loss: 0.2074, Val Acc: 0.8442\n",
            "Epoch [45/70] Train Loss: 0.2011, Train Acc: 0.8795 Val Loss: 0.2044, Val Acc: 0.8636\n",
            "Epoch [46/70] Train Loss: 0.1909, Train Acc: 0.8730 Val Loss: 0.2064, Val Acc: 0.8506\n",
            "Epoch [47/70] Train Loss: 0.2038, Train Acc: 0.8681 Val Loss: 0.2046, Val Acc: 0.8636\n",
            "Epoch [48/70] Train Loss: 0.1983, Train Acc: 0.8697 Val Loss: 0.2043, Val Acc: 0.8636\n",
            "Epoch [49/70] Train Loss: 0.1927, Train Acc: 0.8730 Val Loss: 0.2017, Val Acc: 0.8831\n",
            "Epoch [50/70] Train Loss: 0.1927, Train Acc: 0.8599 Val Loss: 0.2024, Val Acc: 0.8766\n",
            "Epoch [51/70] Train Loss: 0.1910, Train Acc: 0.8681 Val Loss: 0.2015, Val Acc: 0.8636\n",
            "Epoch [52/70] Train Loss: 0.2044, Train Acc: 0.8730 Val Loss: 0.2043, Val Acc: 0.8506\n",
            "Epoch [53/70] Train Loss: 0.1956, Train Acc: 0.8762 Val Loss: 0.2091, Val Acc: 0.8312\n",
            "Epoch [54/70] Train Loss: 0.2000, Train Acc: 0.8648 Val Loss: 0.2052, Val Acc: 0.8312\n",
            "Epoch [55/70] Train Loss: 0.1947, Train Acc: 0.8664 Val Loss: 0.2061, Val Acc: 0.8571\n",
            "Epoch [56/70] Train Loss: 0.2015, Train Acc: 0.8762 Val Loss: 0.2042, Val Acc: 0.8506\n",
            "Epoch [57/70] Train Loss: 0.1935, Train Acc: 0.8746 Val Loss: 0.2037, Val Acc: 0.8506\n",
            "Epoch [58/70] Train Loss: 0.1938, Train Acc: 0.8697 Val Loss: 0.2059, Val Acc: 0.8377\n",
            "Epoch [59/70] Train Loss: 0.1898, Train Acc: 0.8664 Val Loss: 0.2060, Val Acc: 0.8506\n",
            "Epoch [60/70] Train Loss: 0.1891, Train Acc: 0.8795 Val Loss: 0.2022, Val Acc: 0.8571\n",
            "Epoch [61/70] Train Loss: 0.1946, Train Acc: 0.8599 Val Loss: 0.2083, Val Acc: 0.8506\n",
            "Epoch [62/70] Train Loss: 0.2011, Train Acc: 0.8616 Val Loss: 0.2060, Val Acc: 0.8506\n",
            "Epoch [63/70] Train Loss: 0.2020, Train Acc: 0.8583 Val Loss: 0.2048, Val Acc: 0.8442\n",
            "Epoch [64/70] Train Loss: 0.2000, Train Acc: 0.8697 Val Loss: 0.2063, Val Acc: 0.8506\n",
            "Epoch [65/70] Train Loss: 0.2015, Train Acc: 0.8746 Val Loss: 0.2054, Val Acc: 0.8506\n",
            "Epoch [66/70] Train Loss: 0.1984, Train Acc: 0.8746 Val Loss: 0.2047, Val Acc: 0.8506\n",
            "Epoch [67/70] Train Loss: 0.1937, Train Acc: 0.8730 Val Loss: 0.2050, Val Acc: 0.8312\n",
            "Epoch [68/70] Train Loss: 0.1974, Train Acc: 0.8550 Val Loss: 0.2047, Val Acc: 0.8506\n",
            "Epoch [69/70] Train Loss: 0.1928, Train Acc: 0.8664 Val Loss: 0.2046, Val Acc: 0.8766\n",
            "Epoch [70/70] Train Loss: 0.1948, Train Acc: 0.8583 Val Loss: 0.2045, Val Acc: 0.8506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ... (기존 코드 끝난 부분 바로 아래에 추가)\n",
        "\n",
        "# --- Fine-tuning 단계 시작 ---\n",
        "print(\"\\n=== Fine-tuning 단계 시작 ===\")\n",
        "\n",
        "# 1. 모든 파라미터 학습 가능하도록 변경 (unfreeze)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# 2. 옵티마이저 재정의 (학습률 매우 작게 설정)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
        "\n",
        "num_finetune_epochs = 10\n",
        "\n",
        "for epoch in range(1, num_finetune_epochs + 1):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * images.size(0)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss /= total\n",
        "    train_acc = correct / total\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss /= total\n",
        "    val_acc = correct / total\n",
        "\n",
        "    print(f\"[Fine-tune Epoch {epoch}/{num_finetune_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} \"\n",
        "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "DbehN97o6PrD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9b7f7a1-d650-47ce-cfd0-27119cabe690"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fine-tuning 단계 시작 ===\n",
            "[Fine-tune Epoch 1/10] Train Loss: 0.1943, Train Acc: 0.8697 Val Loss: 0.2045, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 2/10] Train Loss: 0.1881, Train Acc: 0.8567 Val Loss: 0.2037, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 3/10] Train Loss: 0.1878, Train Acc: 0.8746 Val Loss: 0.2043, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 4/10] Train Loss: 0.1876, Train Acc: 0.8697 Val Loss: 0.2045, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 5/10] Train Loss: 0.1912, Train Acc: 0.8697 Val Loss: 0.2042, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 6/10] Train Loss: 0.1918, Train Acc: 0.8697 Val Loss: 0.2039, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 7/10] Train Loss: 0.1870, Train Acc: 0.8730 Val Loss: 0.2040, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 8/10] Train Loss: 0.1894, Train Acc: 0.8583 Val Loss: 0.2038, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 9/10] Train Loss: 0.1870, Train Acc: 0.8827 Val Loss: 0.2041, Val Acc: 0.8506\n",
            "[Fine-tune Epoch 10/10] Train Loss: 0.1861, Train Acc: 0.8811 Val Loss: 0.2036, Val Acc: 0.8506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 완료 후 모델 저장\n",
        "torch.save(model.state_dict(), \"drive_model.pth\")\n",
        "print(\"모델 저장 완료: drive_model.pth\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgOJ65mx7KIE",
        "outputId": "cbaccca9-e6ce-4900-bc96-7141c4495db7"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 저장 완료: drive_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DX1lz-G_p3GA",
        "outputId": "422697a1-1698-413c-a6e9-7e1b1e88cda4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y tesseract-ocr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d49N6W70p5d6",
        "outputId": "3bd88d40-282d-4bb1-c549-df255a071db3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\u001b[33m\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.82)] [\u001b[0m\r                                                                               \rGet:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,305 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,561 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,747 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,798 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,051 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,253 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.2 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,994 kB]\n",
            "Fetched 23.2 MB in 3s (6,622 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "39 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    }
  ]
}