# -*- coding: utf-8 -*-
"""cnnmodel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V7SOTuLTdnUK5hwYwKhCqcqBL-nZMraJ
"""

import os
import pandas as pd
import cv2
import numpy as np

DATA_DIR = '/content/drive/MyDrive/data/data'
csv_path = os.path.join(DATA_DIR, 'drive_log.csv')

# CSV 읽기
df = pd.read_csv(csv_path)
print(df.head())

# 이미지와 라벨 불러오기 함수 예시
def load_data(df, data_dir):
    images = []
    labels = []
    for idx, row in df.iterrows():
        img_path = os.path.join(data_dir, row['frame'])
        img = cv2.imread(img_path)
        if img is None:
            continue
        img = cv2.resize(img, (64, 64))  # 모델에 맞게 크기 조절
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        images.append(img)

        # 라벨: 'left', 'center', 'right' -> 숫자 라벨로 변환
        if row['label'] == 'left':
            labels.append(0)
        elif row['label'] == 'center':
            labels.append(1)
        else:
            labels.append(2)
    return np.array(images), np.array(labels)

X, y = load_data(df, DATA_DIR)
print(f"데이터 개수: {len(X)}")
print(f"이미지 형태: {X.shape}")
print(f"라벨 형태: {y.shape}")

import os
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader, random_split
import torchvision.transforms as transforms
import torch.nn as nn
import torch.nn.functional as F

# 1) 커스텀 데이터셋 클래스
class DriveDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        import pandas as pd
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform
        self.label_map = {"left":0, "center":1, "right":2}

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        img_path = os.path.join(self.img_dir, self.data.iloc[idx, 0])
        image = Image.open(img_path).convert("RGB")
        label_str = self.data.iloc[idx, 2]
        label = self.label_map[label_str]
        if self.transform:
            image = self.transform(image)
        return image, label

# 2) 이미지 전처리 + Augmentation 추가
transform = transforms.Compose([
    transforms.Resize((64,64)),
    transforms.RandomHorizontalFlip(),     # 좌우 반전
    transforms.RandomRotation(10),         # ±10도 회전
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))
])

# 3) 데이터 로딩 및 분할
dataset = DriveDataset(csv_file="/content/drive/MyDrive/data/data/drive_log.csv",
                       img_dir="/content/drive/MyDrive/data/data",
                       transform=transform)
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_set, val_set = random_split(dataset, [train_size, val_size])
train_loader = DataLoader(train_set, batch_size=32, shuffle=True)
val_loader = DataLoader(val_set, batch_size=32, shuffle=False)

# 4) Dropout 추가된 CNN 모델 정의
class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.pool = nn.MaxPool2d(2,2)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.dropout = nn.Dropout(0.5)  # Dropout 추가
        self.fc1 = nn.Linear(32*16*16, 64)
        self.fc2 = nn.Linear(64, 3)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))  # 64→32
        x = self.pool(F.relu(self.conv2(x)))  # 32→16
        x = x.view(-1, 32*16*16)
        x = self.dropout(F.relu(self.fc1(x)))  # Dropout 적용
        x = self.fc2(x)
        return x

model = SimpleCNN()
print("✅ Dropout과 Augmentation 적용된 모델 준비 완료!")

import torch.optim as optim

# 1) 장치 설정 (GPU가 있으면 사용)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# 2) 손실 함수 및 옵티마이저
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 3) 학습 루프
num_epochs = 100
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    correct = 0
    total = 0

    for images, labels in train_loader:
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    train_acc = correct / total

    # 검증 단계
    model.eval()
    val_loss = 0.0
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in val_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            val_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    val_acc = correct / total

    print(f"Epoch [{epoch+1}/{num_epochs}] "
          f"Train Loss: {train_loss/len(train_loader):.4f}, Train Acc: {train_acc:.4f} "
          f"Val Loss: {val_loss/len(val_loader):.4f}, Val Acc: {val_acc:.4f}")

torch.save(model.state_dict(), "model.pth")